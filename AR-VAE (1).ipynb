{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7d119e-1af4-4404-8f7a-c83755821ab6",
   "metadata": {},
   "source": [
    "# AR-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b62062-62ba-435b-8b4e-127aed3c5eef",
   "metadata": {},
   "source": [
    "We consider AR-VAE, a variational autoencoder in which the prior is parameterized by an autoregressive model rather than a standard Gaussian. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0466a-eeb3-4c9a-8eee-771bf8b62893",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abd2017-c6da-4d43-92f6-aeccdb7ecf3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:06:17.414948Z",
     "iopub.status.busy": "2023-11-09T10:06:17.414572Z",
     "iopub.status.idle": "2023-11-09T10:06:24.985771Z",
     "shell.execute_reply": "2023-11-09T10:06:24.984905Z",
     "shell.execute_reply.started": "2023-11-09T10:06:17.414923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2022.3.0 requires fsspec==2022.3.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#@markdown\n",
    "\n",
    "!pip -q install datasets pychalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5681a5-d5e2-40e4-82ec-17932b43ea35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:06:24.987553Z",
     "iopub.status.busy": "2023-11-09T10:06:24.987227Z",
     "iopub.status.idle": "2023-11-09T10:06:28.648545Z",
     "shell.execute_reply": "2023-11-09T10:06:28.647810Z",
     "shell.execute_reply.started": "2023-11-09T10:06:24.987528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9540156-f347-4fda-a9b3-9c25da42c968",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5819cbb8-35c9-45f7-b38e-913f189f33d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T13:09:43.409349Z",
     "iopub.status.busy": "2023-11-08T13:09:43.408965Z",
     "iopub.status.idle": "2023-11-08T13:09:43.416685Z",
     "shell.execute_reply": "2023-11-08T13:09:43.415973Z",
     "shell.execute_reply.started": "2023-11-08T13:09:43.409315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "class CelebAFaces(Dataset):\n",
    "    \"\"\"CelebA faces dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    resolution: int - Image resolution.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    \n",
    "    >>> dataset = CelebAFaces(resolution=256)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, resolution: int) -> None:\n",
    "        \"\"\"Initializes the dataset.\"\"\"\n",
    "        \n",
    "        self.resolution = resolution\n",
    "        \n",
    "        # Load the dataset in streaming mode from Hugging Face.\n",
    "        \n",
    "        self._dataset = load_dataset(\n",
    "            path='nielsr/CelebA-faces', \n",
    "            split='train', \n",
    "            streaming=True,\n",
    "        ).shuffle()\n",
    "        \n",
    "        # Create an iterator for the dataset.\n",
    "        \n",
    "        self._dataset_iterator = iter(self._dataset)\n",
    "        \n",
    "        # Define a transform to be applied to each example.\n",
    "        \n",
    "        self._transform = transforms.Compose([\n",
    "            transforms.Resize(\n",
    "                size=(self.resolution, self.resolution),\n",
    "                interpolation=0,\n",
    "            ),\n",
    "            transforms.PILToTensor(),\n",
    "            transforms.Lambda(lambda x: x / 255.),\n",
    "        ])\n",
    "        \n",
    "        # Get the length of the dataset.\n",
    "        \n",
    "        self._length = self._dataset.info.splits['train'].num_examples\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        \n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.Tensor:\n",
    "        \"\"\"Returns an example from the dataset.\"\"\"\n",
    "        \n",
    "        example = next(self._dataset_iterator)['image']\n",
    "        example = self._transform(example)\n",
    "        \n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40c0aa8-66f2-4af1-a76c-ec7ab38dd64a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T13:09:48.888425Z",
     "iopub.status.busy": "2023-11-08T13:09:48.888030Z",
     "iopub.status.idle": "2023-11-08T13:09:49.327104Z",
     "shell.execute_reply": "2023-11-08T13:09:49.326526Z",
     "shell.execute_reply.started": "2023-11-08T13:09:48.888398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "train_dataset = CelebAFaces(resolution=128)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13023b0-7e72-4c23-9f67-45839b43f78f",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09e9052-853f-4139-996b-f5774d3440c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:06:28.650665Z",
     "iopub.status.busy": "2023-11-09T10:06:28.650031Z",
     "iopub.status.idle": "2023-11-09T10:06:28.655896Z",
     "shell.execute_reply": "2023-11-09T10:06:28.655077Z",
     "shell.execute_reply.started": "2023-11-09T10:06:28.650629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "@dataclass\n",
    "class CausalCNNOptions:\n",
    "    \"\"\"Causal CNN options.\"\"\"\n",
    "\n",
    "    hidden_channels: int\n",
    "    kernel_size: int\n",
    "    vocabulary_size: int\n",
    "    sequence_length: int\n",
    "    embedding_dimension: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4299250-fb49-4b4b-88a2-eec5e641285c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:06:28.657390Z",
     "iopub.status.busy": "2023-11-09T10:06:28.657176Z",
     "iopub.status.idle": "2023-11-09T10:06:28.670069Z",
     "shell.execute_reply": "2023-11-09T10:06:28.669239Z",
     "shell.execute_reply.started": "2023-11-09T10:06:28.657372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "class CausalCNN(nn.Module):\n",
    "    \"\"\"Causal CNN.\"\"\"\n",
    "    \n",
    "    def __init__(self, options: CausalCNNOptions) -> None:\n",
    "        \"\"\"Initializes the module.\"\"\"\n",
    "        \n",
    "        super(CausalCNN, self).__init__()\n",
    "        self.options = options\n",
    "        \n",
    "        self.position_embedding = nn.Embedding(num_embeddings=options.sequence_length, embedding_dim=options.embedding_dimension)\n",
    "        \n",
    "        self.convolution_1 = nn.Conv1d(in_channels=options.embedding_dimension + options.vocabulary_size, out_channels=options.hidden_channels, kernel_size=options.kernel_size, stride=1, padding=0, dilation=1)\n",
    "        self.convolution_2 = nn.Conv1d(in_channels=options.hidden_channels, out_channels=options.hidden_channels, kernel_size=options.kernel_size, stride=1, padding=0, dilation=2)\n",
    "        self.convolution_3 = nn.Conv1d(in_channels=options.hidden_channels, out_channels=options.hidden_channels, kernel_size=options.kernel_size, stride=1, padding=0, dilation=4)\n",
    "        self.convolution_4 = nn.Conv1d(in_channels=options.hidden_channels, out_channels=options.hidden_channels, kernel_size=options.kernel_size, stride=1, padding=0, dilation=16)\n",
    "        self.convolution_5 = nn.Conv1d(in_channels=options.hidden_channels, out_channels=options.hidden_channels, kernel_size=options.kernel_size, stride=1, padding=0, dilation=64)\n",
    "        self.convolution_6 = nn.Conv1d(in_channels=options.hidden_channels, out_channels=options.vocabulary_size, kernel_size=options.kernel_size, stride=1, padding=0, dilation=128)\n",
    "\n",
    "        self.padding_1 = (self.options.kernel_size, -1)\n",
    "        self.padding_2 = ((self.options.kernel_size - 1) * 2, 0, 0, 0)\n",
    "        self.padding_3 = ((self.options.kernel_size - 1) * 4, 0, 0, 0)\n",
    "        self.padding_4 = ((self.options.kernel_size - 1) * 16, 0, 0, 0)\n",
    "        self.padding_5 = ((self.options.kernel_size - 1) * 64, 0, 0, 0)\n",
    "        self.padding_6 = ((self.options.kernel_size - 1) * 128, 0, 0, 0)\n",
    "        \n",
    "    def forward(self, tokens: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        \n",
    "        # Embeddings.\n",
    " \n",
    "        tokens = tokens.to(int).cuda()\n",
    "        positions = torch.arange(self.options.sequence_length).to(int).cuda()\n",
    "        positions = positions.view(1, -1).repeat(tokens.size(0), 1)\n",
    "        \n",
    "        token_embeddings = F.one_hot(tokens, num_classes=self.options.vocabulary_size)\n",
    "        position_embeddings = self.position_embedding(positions)\n",
    "        \n",
    "        x = torch.cat((token_embeddings, position_embeddings), dim=-1)\n",
    "        \n",
    "        # CNN.\n",
    "        \n",
    "        x = x.transpose(-2, -1)\n",
    "        x = F.leaky_relu(self.convolution_1(F.pad(x, self.padding_1)))\n",
    "        x = F.leaky_relu(self.convolution_2(F.pad(x, self.padding_2))) #+ x\n",
    "        x = F.leaky_relu(self.convolution_3(F.pad(x, self.padding_3))) #+ x\n",
    "        x = F.leaky_relu(self.convolution_4(F.pad(x, self.padding_4))) #+ x\n",
    "        x = F.leaky_relu(self.convolution_5(F.pad(x, self.padding_5))) #+ x\n",
    "        x = self.convolution_6(F.pad(x, self.padding_6))\n",
    "        x = x.transpose(-2, -1)\n",
    "        \n",
    "        # Logits.\n",
    "        \n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "dec08076-6051-4c3f-852e-8d1585ad11a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T19:00:37.491200Z",
     "iopub.status.busy": "2023-11-08T19:00:37.490816Z",
     "iopub.status.idle": "2023-11-08T19:00:37.496242Z",
     "shell.execute_reply": "2023-11-08T19:00:37.495560Z",
     "shell.execute_reply.started": "2023-11-08T19:00:37.491174Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27458"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0618a4-199a-4bc6-81a6-8ce06668198c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:06:42.895653Z",
     "iopub.status.busy": "2023-11-09T10:06:42.895238Z",
     "iopub.status.idle": "2023-11-09T10:06:42.965022Z",
     "shell.execute_reply": "2023-11-09T10:06:42.964171Z",
     "shell.execute_reply.started": "2023-11-09T10:06:42.895625Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "mnist_dataset = MNIST(root='.', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.round()),\n",
    "]))\n",
    "\n",
    "mnist_dataloader = DataLoader(dataset=mnist_dataset, shuffle=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "bb6cb204-b1c6-42fb-8a74-da43b3c974ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:45:13.329147Z",
     "iopub.status.busy": "2023-11-09T10:45:13.328755Z",
     "iopub.status.idle": "2023-11-09T10:45:13.333505Z",
     "shell.execute_reply": "2023-11-09T10:45:13.332624Z",
     "shell.execute_reply.started": "2023-11-09T10:45:13.329121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown\n",
    "\n",
    "#model = CausalCNN(CausalCNNOptions(hidden_channels=32, kernel_size=6, sequence_length=28*28, vocabulary_size=2, embedding_dimension=2)).cuda()\n",
    "#model = torch.load('./causal-cnn-mnist-2.pt')\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "93deac62-d6ff-4970-bf77-99d7688a850b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:56:02.024370Z",
     "iopub.status.busy": "2023-11-09T10:56:02.023586Z",
     "iopub.status.idle": "2023-11-09T10:57:15.327681Z",
     "shell.execute_reply": "2023-11-09T10:57:15.326852Z",
     "shell.execute_reply.started": "2023-11-09T10:56:02.024340Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/5, batch 1/468 - 0.0765201672911644\n",
      "epoch 1/5, batch 101/468 - 0.07244537025690079\n",
      "epoch 1/5, batch 201/468 - 0.07532253861427307\n",
      "epoch 1/5, batch 301/468 - 0.0751049593091011\n",
      "epoch 1/5, batch 401/468 - 0.07580901682376862\n",
      "epoch 2/5, batch 1/468 - 0.07420516759157181\n",
      "epoch 2/5, batch 101/468 - 0.07745398581027985\n",
      "epoch 2/5, batch 201/468 - 0.0743526816368103\n",
      "epoch 2/5, batch 301/468 - 0.07411393523216248\n",
      "epoch 2/5, batch 401/468 - 0.07624170929193497\n",
      "epoch 3/5, batch 1/468 - 0.0742465928196907\n",
      "epoch 3/5, batch 101/468 - 0.0736582800745964\n",
      "epoch 3/5, batch 201/468 - 0.07644883543252945\n",
      "epoch 3/5, batch 301/468 - 0.07522011548280716\n",
      "epoch 3/5, batch 401/468 - 0.07101801782846451\n",
      "epoch 4/5, batch 1/468 - 0.07387808710336685\n",
      "epoch 4/5, batch 101/468 - 0.07488328218460083\n",
      "epoch 4/5, batch 201/468 - 0.07749556750059128\n",
      "epoch 4/5, batch 301/468 - 0.07463105022907257\n",
      "epoch 4/5, batch 401/468 - 0.07692161202430725\n",
      "epoch 5/5, batch 1/468 - 0.07289910316467285\n",
      "epoch 5/5, batch 101/468 - 0.07640796154737473\n",
      "epoch 5/5, batch 201/468 - 0.07110683619976044\n",
      "epoch 5/5, batch 301/468 - 0.07541101425886154\n",
      "epoch 5/5, batch 401/468 - 0.07019514590501785\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_index, (y, _) in enumerate(mnist_dataloader):\n",
    "        if (len(y) != 128):\n",
    "            continue\n",
    "            \n",
    "        y = y.to(int).cuda().view(128, 28*28)\n",
    "        yp = model(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(yp.view(-1, 2), y.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_index % 100) == 0:\n",
    "            print(f'epoch {epoch + 1}/{epochs}, batch {batch_index + 1}/{len(mnist_dataset)//128} - {loss.detach().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b9d27f65-eab6-4ef9-bf36-3f09fab287f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:33:29.930350Z",
     "iopub.status.busy": "2023-11-09T10:33:29.929934Z",
     "iopub.status.idle": "2023-11-09T10:33:29.936896Z",
     "shell.execute_reply": "2023-11-09T10:33:29.935960Z",
     "shell.execute_reply.started": "2023-11-09T10:33:29.930324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_greedy(model: CausalCNN, batch_size: int, prefix: torch.Tensor = None) -> torch.Tensor:\n",
    "    \"\"\"Samples from a CausalCNN.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    sequence_length = model.options.sequence_length\n",
    "    position = 0\n",
    "    sample = torch.zeros((batch_size, sequence_length))\n",
    "    \n",
    "    if prefix is not None:\n",
    "        position = prefix.size(0)\n",
    "        sample[:, : position] = prefix\n",
    "    \n",
    "    for i in range(position, sequence_length):\n",
    "        logits = model(sample)[:, i, 1].detach()\n",
    "        probabilities = torch.exp(logits)\n",
    "        values = torch.rand(batch_size).cuda() < probabilities\n",
    "        \n",
    "        sample[:, i] = values\n",
    "    \n",
    "    sample = sample.view(batch_size, 1, 28, 28)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93cf7ae5-d507-4b70-9a5d-911c66bae856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:08:27.946445Z",
     "iopub.status.busy": "2023-11-09T10:08:27.946038Z",
     "iopub.status.idle": "2023-11-09T10:08:27.950398Z",
     "shell.execute_reply": "2023-11-09T10:08:27.949702Z",
     "shell.execute_reply.started": "2023-11-09T10:08:27.946421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_prefix(model, prefix):\n",
    "    \n",
    "    sequence_length = model.options.sequence_length\n",
    "    offset = prefix.size(0)\n",
    "\n",
    "    sample = torch.zeros(sequence_length).cuda()\n",
    "    sample[: offset] = prefix\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba21aec5-09a4-4911-a54b-ec36d8874893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:08:28.464301Z",
     "iopub.status.busy": "2023-11-09T10:08:28.463933Z",
     "iopub.status.idle": "2023-11-09T10:08:28.469253Z",
     "shell.execute_reply": "2023-11-09T10:08:28.468594Z",
     "shell.execute_reply.started": "2023-11-09T10:08:28.464274Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_distribution(model, prefix):\n",
    "    model.eval()\n",
    "        \n",
    "    sequence_length = model.options.sequence_length\n",
    "    offset = 0\n",
    "    sample = torch.zeros(sequence_length).cuda()\n",
    "    \n",
    "    if prefix is not None:\n",
    "        offset = prefix.size(0)\n",
    "        sample[: offset] = prefix\n",
    "    \n",
    "    logits = model(sample.view(1, sequence_length)).detach()\n",
    "    probability = torch.exp(logits)[0,:,1]\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b0e01114-0a33-4dc8-8f56-c3009d75311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:58:57.949780Z",
     "iopub.status.busy": "2023-11-09T10:58:57.949378Z",
     "iopub.status.idle": "2023-11-09T10:58:57.957503Z",
     "shell.execute_reply": "2023-11-09T10:58:57.956762Z",
     "shell.execute_reply.started": "2023-11-09T10:58:57.949746Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAABe0lEQVR4nO3cwU6DUBRF0db4/79cJ51gyAvQ9/DkuNZUod25yS2h4uMBAAAAAAAAAAAA/9Fz6dlfp4+4/H6+rh6YRkgaIWlqQhat3/N7d+v826qZiJA0QtLUhHxPOs9w3+4u00839C81ExGSRkiampCP1+/5vTvk5oOQNELSCElz/S7K/gfIgfNdPnCoZiJC0ghJUxMy6y7Kke05+b7JVs1EhKQRkqYmZNb6HVq6d99qJiIkjZA0NSEX1u+RZbr7O8/jx59XMxEhaYSkqQmZfe/3wIu8Rj+8rGYiQtIISVMTsvbmw9qnUzZqJiIkjZA0NSE3LshFf/LwVjMRIWmEpBGS5pbvEHdN/gSrmYiQNELS1ITcchm/vX5f85I1ExGSRkgaIWmEpBGSRkgaIWmEpBGSpibkzn8BuvS1aiYiJI2QNDUhi756u+OBva2aiQhJIyRNTcjsK9LRc3tL1UxESBohaYSkEZJGSBohaWpCPIeYRkgaIWlqQgD4Ez+8axQotV5lVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = mnist_dataset[45][0]\n",
    "\n",
    "transforms.ToPILImage()(example).resize((200, 200), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1b5f43f4-8060-4fa9-b09f-cb79ad1b8e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:59:33.168528Z",
     "iopub.status.busy": "2023-11-09T10:59:33.168135Z",
     "iopub.status.idle": "2023-11-09T10:59:33.176048Z",
     "shell.execute_reply": "2023-11-09T10:59:33.175241Z",
     "shell.execute_reply.started": "2023-11-09T10:59:33.168505Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAAAPUlEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8GadCAABYe850QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = example.flatten()[: 10]\n",
    "\n",
    "transforms.ToPILImage()(show_prefix(model, prefix).view(28, 28)).resize((200, 200), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "22f6ebce-8ae8-497a-bfa4-d808f4dfbbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:59:34.328947Z",
     "iopub.status.busy": "2023-11-09T10:59:34.328580Z",
     "iopub.status.idle": "2023-11-09T10:59:34.337305Z",
     "shell.execute_reply": "2023-11-09T10:59:34.336593Z",
     "shell.execute_reply.started": "2023-11-09T10:59:34.328922Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAAAAACIM/FCAAADHklEQVR4nO2dwW7bMBBEKdtN0v//1ARFE9tRDl4CGWJKWElRrLbvXYilSUsDAuPFiqJbAwAAAAD4X1iyfO36zSsevjk/DQjJBkKyUUbI37Jf/z3LJFqH1kUbKLMiCMkGQrKBkGx8/XdkkebQXKhNED8V701a7X13M6aUWRGEZAMh2SgjZIv96ljvsMfZhzfUb9tVQo2sNXvKrAhCsoGQbJQRcrpn0OIatdaw3R6epIkZ6qLnJr3a6IVXiXwyXGZFEJINhGSjjJB59hufHqWx9vsjZjzI0Cf5Ni0svDUXRnSRSDPjIUNuch/7ByHZQEg2yggZsl/12/7pwY3xBVntDReNRFeLBz2Ka4R/X2WM+m7/zN5AmRVBSDYQko0yQrr92pS2W6RWHdbZDK0hnF1nDH3UG4neV4k0X/abPnT+/kFINhCSjTJCTrO67lB1WN3QnihbtDJhixf9ByAsNjLc8O2LND1fxn53AUKygZBslBHinyF2x7Z7pxeZOZi6LW3or0JM/BljjvJhk8iWqz1lVgQh2UBINsoIGex32EgRLhhqNf++Smc3ajXcVb5mkYm9JB32++vWvNyaV3s7M8qsCEKygZBslBFysq8B9k67ZVkfBQ4Jqpa9Y8aDdIYZP+sMLXvr7QzwDHEXICQbCMmGLz74ioJ9p05T2t6rpe0Y8yRRpLtD9VpT6w2UWRGEZAMh2SgjpNvv8IqGYpNQrSEMQw7SGxc5y4x+Kc1+tc7hb45niLsAIdlASDbuen0vUBecni+hO49/35o3GTI4/bBLbgbFh12AkGwgJBtb3p620fTpmKbGusdh0TGzKw6Q/e4ChGQDIdkoI8Rv4fA7saOxpxZ1dEeH5uYXN9Kfu2Hv6g+h3vLuQUg2EJKNMkL8a+DN9uqrL/awzs4d50P3Tj1FaXYG3ZQyK4KQbCAkG2WE+Ox3CDXDtU8NB9/esPNYLXZ2It2UMiuCkGwgJBtlhNx1Bp1G+lK4T1A3+Kb/e5XNlFkRhGQDIdkoI+QLB+DbI5GmBxT9C8qsCEKygZBslBECAAAAAAAAAAAAAAAAAPCZD9/pu8NCv5DTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=200x200>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.ToPILImage()(show_distribution(model, prefix).view(28, 28)).resize((200,200),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f1475ef4-0e3f-42c1-b2ba-310ef8093ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T11:49:00.839228Z",
     "iopub.status.busy": "2023-11-09T11:49:00.838797Z",
     "iopub.status.idle": "2023-11-09T11:49:04.154003Z",
     "shell.execute_reply": "2023-11-09T11:49:04.153235Z",
     "shell.execute_reply.started": "2023-11-09T11:49:00.839203Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_image(sample_greedy(model, batch_size=128, prefix=prefix), './completions2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f870c953-bf9d-4dd1-99bf-6820747f9674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T10:13:32.135832Z",
     "iopub.status.busy": "2023-11-09T10:13:32.135426Z",
     "iopub.status.idle": "2023-11-09T10:13:32.142536Z",
     "shell.execute_reply": "2023-11-09T10:13:32.141898Z",
     "shell.execute_reply.started": "2023-11-09T10:13:32.135804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'causal-cnn-mnist-3.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
